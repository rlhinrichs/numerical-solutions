{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1184abe7",
   "metadata": {},
   "source": [
    "<center><h1>Homework 2</h1>\n",
    "    <h3>Rebecca Hinrichs</h3>\n",
    "    <h4>MATH 4301 Spring 2023</h4></center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7179b472",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries & dependencies\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import array, zeros, diag, sqrt\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import rand\n",
    "from scipy.sparse import diags\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # suppress ill-conditioned warnings\n",
    "np.set_printoptions(precision = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce6b32-77a1-4d14-a29f-788a058a1bca",
   "metadata": {},
   "source": [
    "<center><br>Questions are from <b>Problem Set 2.3</b> in <br><i>Numerical Methods in Engineering with Python 3</i> by Jaan Kiusalaas</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf623f",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2>Question 12</h2></center>\n",
    "Solve the following equations with the Gauss-Seidel method: \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "12 & -2 & 3 & 1 \\\\\n",
    "-2 & 15 & 6 & -3 \\\\\n",
    "1 & 6 & 20 & -4 \\\\\n",
    "0 & -3 & 2 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4 \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "20 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d03ff12d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of equations ==>  4\n",
      "\n",
      "Total Number of Iterations = 29\n",
      "\n",
      "Norm of the Residual Vector::\n",
      " 8.13460847711607e-09\n",
      "\n",
      "The solution Vector x =\n",
      " [-0.3344 -0.5722  1.1013 -0.4355]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [ 0.  0. 20. -0.] \n",
      "\t→b: [ 0.  0. 20.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Gauss-Seidel Method\n",
    "A = array([[ 12, -2,  3,  1 ],\n",
    "           [ -2, 15,  6, -3 ],\n",
    "           [  1,  6, 20, -4 ],\n",
    "           [  0, -3,  2,  9 ] ], float)\n",
    "b = array( [ 0, 0, 20, 0 ], float)\n",
    "\n",
    "# Initial Approximation:: set x=0\n",
    "x = array([0, 0, 0, 0], float )\n",
    "\n",
    "## Define functions for iterative technique\n",
    "def gaussSeidel(iterEqs, x,tol = 1.0e-9):\n",
    "    omega = 1  # no relaxation\n",
    "    k = 10\n",
    "    p = 1\n",
    "    imax = 100\n",
    "    for i in range(1, imax):\n",
    "        xOld = x.copy()\n",
    "        x = iterEqs(x, omega)\n",
    "        dx = x - xOld\n",
    "        dx = sqrt( dx @ dx )\n",
    "        if dx < tol:\n",
    "            return x,i,omega\n",
    "        # Compute relaxation factor after k+p iterations\n",
    "        if i == k: dx1 = dx\n",
    "        if i == k + p:\n",
    "            dx2 = dx\n",
    "            omega = 2.0/(1.0 + math.sqrt(1.0 - (dx2/dx1)**(1.0/p)))\n",
    "    return x,i,omega\n",
    "def iterEqs(x, omega = 1): \n",
    "    gs_update = ( b - ( A @ x - diag(A) * x ) ) / diag(A) \n",
    "    return  omega * gs_update + (1-omega) * x\n",
    "\n",
    "# Solution\n",
    "x, numIter, omega = gaussSeidel(iterEqs, x)\n",
    "x_orig = x.copy()\n",
    "\n",
    "# Results\n",
    "print(\"\\nNumber of equations ==> \",A.shape[0])\n",
    "print(\"\\nTotal Number of Iterations =\", numIter)\n",
    "# print(\"\\nRelaxation factor =\", omega)\n",
    "print(\"\\nNorm of the Residual Vector::\\n\", np.linalg.norm(A @ x - b))\n",
    "print(\"\\nThe solution Vector x =\\n\", x)\n",
    "print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0ab9f-550f-4616-aa74-18207ce32306",
   "metadata": {},
   "source": [
    "<br>\n",
    "Repeat the above using the $Conjugate Gradient Method$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d764cd-efa8-4c55-b64e-84679488179d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->>> The Conjugate Gradient Method cannot be applied here! <<<---\n",
      "\n",
      "\tA sparse matrix with symmetry is required.\n",
      "\n",
      "Problematic Solution Vector x =\n",
      " [-0.3539 -0.5781  1.1165 -0.4714]\n",
      "\n",
      "Verify A x ≠ b:\n",
      "\t→A x: [-0.2  0.1 20.4 -0.3] \n",
      "\t→b: [ 0.  0. 20.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Conjugate Gradient Method\n",
    "A = array([[ 12, -2,  3,  1 ],\n",
    "           [ -2, 15,  6, -3 ],\n",
    "           [  1,  6, 20, -4 ],\n",
    "           [  0, -3,  2,  9 ] ], float)\n",
    "b = array( [ 0, 0, 20, 0 ], float)\n",
    "\n",
    "# Initial Approximation:: set x=0\n",
    "x = array([0, 0, 0, 0], float )\n",
    "\n",
    "## Define functions for iterative technique\n",
    "def conjGrad(Av,x,b,tol=1.0e-9):\n",
    "    n = len(b)\n",
    "    r = b - Av(x)\n",
    "    s = r.copy()\n",
    "    for i in range(n):\n",
    "        u = Av(s)\n",
    "        alpha = np.dot(s,r)/np.dot(s,u)\n",
    "        x = x + alpha*s\n",
    "        r = b - Av(x)\n",
    "        if(math.sqrt(np.dot(r,r))) < tol:\n",
    "            break\n",
    "        else:\n",
    "            beta = -np.dot(r,u)/np.dot(s,u)\n",
    "            s = r + beta*s\n",
    "    return x,i\n",
    "def Ax(v):\n",
    "    n = len(v)\n",
    "    Ax = np.zeros(n)\n",
    "    Ax[0] = 12.0*v[0] - 2.0*v[1] + 3.0*v[2] + v[3]\n",
    "    Ax[1:n-2] = -2.0*v[0:n-3] + 15.0*v[1:n-2] + 6.0*v[2:n-1] - 3.0*v[3:n]\n",
    "    Ax[2:n-1] = v[0:n-3] + 6.0*v[1:n-2] + 20.0*v[2:n-1] - 4.0*v[3:n]\n",
    "    Ax[n-1] = -3.0*v[n-3] + 2.0*v[n-2] + 9.0*v[n-1]\n",
    "    if np.isnan(Ax).any():\n",
    "        print('NaN found!')\n",
    "    return Ax\n",
    "\n",
    "# Solution\n",
    "x, numIter = conjGrad(Ax,x,b,tol=1.0e-9)\n",
    "if np.isnan(x).any() or (A@x).all() != b.all():\n",
    "    print('\\n--->>> The Conjugate Gradient Method cannot be applied here! <<<---\\n')\n",
    "    print('\\tA sparse matrix with symmetry is required.\\n')\n",
    "    print(\"Problematic Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x ≠ b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")\n",
    "else:\n",
    "    # Results\n",
    "    print(\"Number of equations ==> \",A.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", numIter)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(A @ x - b))\n",
    "    print(\"\\nThe Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b2bde",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2>Question 13</h2></center>\n",
    "Use the Gauss-Seidel method with relaxation to solve <b>$Ax = b$</b>, where\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "4 & -1 & 0 & 0 \\\\\n",
    "-1 & 4 & -1 & 0 \\\\\n",
    "0 & -1 & 4 & -1 \\\\\n",
    "0 & 0 & -1 & 3 \\\\\n",
    "\\end{bmatrix}    \n",
    "b = \n",
    "\\begin{bmatrix}\n",
    "15 \\\\\n",
    "10 \\\\\n",
    "10 \\\\\n",
    "10 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Take $x_i = \\frac{b_i}{A_{ii}}$ as the starting vector, and use $\\omega = 1.1$ for the relaxation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d928e991-df4e-4045-be1d-35067dc44192",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->> The Starting Vector x is [3.75   2.5    2.5    3.3333] \n",
      "\n",
      "Number of equations ==>  4\n",
      "\n",
      "Total Number of Iterations = 33\n",
      "\n",
      "Relaxation factor = 1.1\n",
      "\n",
      "Norm of the Residual Vector::\n",
      " 1.9329380228492633e-09\n",
      "\n",
      "The solution Vector x =\n",
      " [5. 5. 5. 5.]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [15. 10. 10. 10.] \n",
      "\t→b: [15. 10. 10. 10.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Gauss-Seidel Method & relaxation omega = 1.1\n",
    "A = array( [[ 4, -1,  0,  0 ], \n",
    "            [-1,  4, -1,  0 ], \n",
    "            [ 0, -1,  4, -1 ], \n",
    "            [ 0,  0, -1,  3 ]], float) \n",
    "b = array( [ 15, 10, 10, 10 ], float)\n",
    "\n",
    "# Initial Approximation:: set x=b/A\n",
    "x = np.zeros(A.shape[0])\n",
    "for i in range(len(b)):\n",
    "    x[i] = b[i]/A[i][i]\n",
    "print('\\n--->> The Starting Vector x is', x, '\\n')\n",
    "\n",
    "# Define functions for iterative technique\n",
    "def gaussSeidel(iterEqs, x,tol = 1.0e-9):\n",
    "    omega = 1.1  # <<-- extrapolation\n",
    "    k = 10\n",
    "    p = 1\n",
    "    imax = 100\n",
    "    for i in range(1, imax):\n",
    "        xOld = x.copy()\n",
    "        x = iterEqs(x, omega)\n",
    "        dx = x - xOld\n",
    "        dx = sqrt( dx @ dx )\n",
    "        if dx < tol:\n",
    "            return x,i,omega\n",
    "    return x,i,omega\n",
    "def iterEqs(x, omega = 1): \n",
    "    gs_update = ( b - ( A @ x - diag(A) * x ) ) / diag(A) \n",
    "    return  omega * gs_update + (1-omega) * x \n",
    "\n",
    "# Solution\n",
    "n = A.shape[0]\n",
    "x, numIter, omega = gaussSeidel(iterEqs, x)\n",
    "# x_orig = x.copy()\n",
    "\n",
    "# Results\n",
    "print(\"Number of equations ==> \",n)\n",
    "print(\"\\nTotal Number of Iterations =\", numIter)\n",
    "print(\"\\nRelaxation factor =\", omega)\n",
    "print(\"\\nNorm of the Residual Vector::\\n\", np.linalg.norm(A @ x - b))\n",
    "print(\"\\nThe solution Vector x =\\n\", x)\n",
    "print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696501fe-b98b-4f43-91e3-d96105d95d6a",
   "metadata": {},
   "source": [
    "<br>\n",
    "Repeat the above using the $Conjugate Gradient Method$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967585af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->> The Starting Vector x is [3.75   2.5    2.5    3.3333] \n",
      "\n",
      "Number of equations ==>  4\n",
      "\n",
      "Total Number of Iterations =  3\n",
      "\n",
      "Norm of the Residual Vector =  0.0\n",
      "\n",
      "The Solution Vector x =\n",
      " [5. 5. 5. 5.]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [15. 10. 10. 10.] \n",
      "\t→b: [15. 10. 10. 10.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Conjugate Gradient Method & relaxation omega = 1.1\n",
    "A = array( [[ 4, -1,  0,  0 ], \n",
    "            [-1,  4, -1,  0 ], \n",
    "            [ 0, -1,  4, -1 ], \n",
    "            [ 0,  0, -1,  3 ]], float) \n",
    "b = array( [ 15, 10, 10, 10 ], float)\n",
    "\n",
    "# Initial Approximation:: set x=b/A\n",
    "x = np.zeros(A.shape[0])\n",
    "for i in range(len(b)):\n",
    "    x[i] = b[i]/A[i][i]\n",
    "print('\\n--->> The Starting Vector x is', x, '\\n')\n",
    "\n",
    "## Define functions for iterative technique\n",
    "def conjGrad(Av,x,b,tol=1.0e-9):\n",
    "    n = len(b)\n",
    "    r = b - Av(x)\n",
    "    s = r.copy()\n",
    "    for i in range(n):\n",
    "        u = Av(s)\n",
    "        alpha = np.dot(s,r)/np.dot(s,u)\n",
    "        x = x + alpha*s\n",
    "        r = b - Av(x)\n",
    "        if(math.sqrt(np.dot(r,r))) < tol:\n",
    "            break\n",
    "        else:\n",
    "            beta = -np.dot(r,u)/np.dot(s,u)\n",
    "            s = r + beta*s\n",
    "    return x,i\n",
    "def Ax(v):\n",
    "    n = len(v)\n",
    "    Ax = np.zeros(n)\n",
    "    Ax[0] = 4.0*v[0] - v[1]\n",
    "    Ax[1:n-1] = -v[0:n-2] + 4.0*v[1:n-1] - v[2:n]\n",
    "    Ax[n-1] = -v[n-2] + 3.0*v[n-1]\n",
    "    if np.isnan(Ax).any():\n",
    "        print('NaN found!')\n",
    "    return Ax\n",
    "\n",
    "# Solution\n",
    "x, numIter = conjGrad(Ax,x,b,tol=1.0e-9)\n",
    "if np.isnan(x).any() or (A@x).all() != b.all():\n",
    "    print('\\n--->>> The Conjugate Gradient Method cannot be applied here! <<<---\\n')\n",
    "    print('\\tA sparse matrix with symmetry is required.\\n')\n",
    "    print(\"Problematic Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x ≠ b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")\n",
    "else:\n",
    "    # Results\n",
    "    print(\"Number of equations ==> \",A.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", numIter)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(A @ x - b))\n",
    "    print(\"\\nThe Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb17dfa",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2>Question 16</h2></center>\n",
    "Write a program for solving <b>$Ax = b$</b> by the Gauss-Seidel method based on the function $\\color{magenta}{\\text{gaussSeidel}}$. Input should consist of the matrix <b>$A$</b> and the vector <b>$b$</b>. Test the program with\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "3 & -2 & 1 & 0 & 0 & 1 \\\\\n",
    "-2 & 4 & -2 & 1 & 0 & 0 \\\\\n",
    "1 & -2 & 4 & -2 & 1 & 0 \\\\\n",
    "0 & 1 & -2 & 4 & -2 & 1 \\\\\n",
    "0 & 0 & 1 & -2 & 4 & -2 \\\\\n",
    "1 & 0 & 0 & 1 & -2 & 3 \\\\\n",
    "\\end{bmatrix}    \n",
    "b = \n",
    "\\begin{bmatrix}\n",
    "10 \\\\\n",
    "-8 \\\\\n",
    "10 \\\\\n",
    "10 \\\\\n",
    "-8 \\\\\n",
    "10 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that <b>$A$</b> is not diagonally dominant, but this does not necessarily preclude convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1eb80d0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--->>> Gauss-Seidel failed to converge within 2000 iterations <<<---\n",
      "\n",
      "\n",
      "Number of equations ==>  6\n",
      "\n",
      "Total Number of Iterations =  1999\n",
      "\n",
      "Norm of the Residual Vector =  nan\n",
      "\n",
      "Problematic Solution Vector x =\n",
      " [nan nan nan nan nan nan]\n",
      "\n",
      "Verify A x ≠ b:\n",
      "\t→A x: [nan nan nan nan nan nan] \n",
      "\t→b: [10. -8. 10. 10. -8. 10.] \n",
      "\n",
      "Suspect that A is positive-indefinite and x is a saddle point?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Gauss-Seidel Method\n",
    "## Define function to re-create A according to input length 'n'\n",
    "def banded_matrix(n):\n",
    "    A0 = diags([1,-2,4,-2,-1],[-2,-1,0,1,2], shape=(n,n)).toarray()\n",
    "    A0[0][0] -= 1  # adjust UL corner\n",
    "    A0[n-1][n-1] -= 1  # adjust LR corner\n",
    "    A0[0][n-1] = 1  # adjust LL corner\n",
    "    A0[n-1][0] = 1  # adjust UR corner\n",
    "    return A0\n",
    "b = array( [10, -8, 10, 10, -8, 10 ], float)\n",
    "    \n",
    "## Define functions for iterative technique\n",
    "def gaussSeidel(a, B):\n",
    "    omega = 1.0  # no relaxation\n",
    "    k = 10\n",
    "    p = 1\n",
    "    imax = 2000  # max iterations\n",
    "    x = zeros(len(B))  # initial approximation:: set x=0\n",
    "    for i in range(1, imax):\n",
    "        xOld = x.copy()\n",
    "        for j in range(len(B)):\n",
    "            gs_update = ( B - ( a @ x - diag(a) * x ) ) / diag(a) \n",
    "        x = omega * gs_update + (1-omega) * x\n",
    "        dx = math.sqrt(np.dot(x-xOld,x-xOld))\n",
    "        if dx < 1.0e-9: return x,i,omega\n",
    "        # Compute relaxation factor after k+p iterations\n",
    "        if i == k: dx1 = dx\n",
    "        if i == k + p:\n",
    "            dx2 = dx\n",
    "            omega = 2.0/(1.0 + math.sqrt(1.0 - (dx2/dx1)**(1.0/p)))\n",
    "    print(f'\\n\\n--->>> Gauss-Seidel failed to converge within', \\\n",
    "          f'{imax} iterations <<<---\\n')\n",
    "    # Results\n",
    "    print(\"\\nNumber of equations ==> \", a.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", i)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(a @ x - B))\n",
    "    return x,i,omega\n",
    "\n",
    "# Solution\n",
    "x = np.zeros(len(b))\n",
    "A = banded_matrix(len(b))\n",
    "x, numIter, omega = gaussSeidel(A, b)\n",
    "\n",
    "# Results\n",
    "if np.isnan(x).any() or (A@x).all() != b.all():\n",
    "    print(\"\\nProblematic Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x ≠ b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")\n",
    "    print('Suspect that A is positive-indefinite and x is a saddle point?\\n')\n",
    "else:\n",
    "    # Results\n",
    "    print(\"\\nThe Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f9787-c778-432f-94c6-561ef9b9b2f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "Repeat the above using the $Conjugate Gradient Method$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e359c56-5fcd-442b-b1f4-86677bf3acc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of equations ==>  6\n",
      "\n",
      "Total Number of Iterations =  2\n",
      "\n",
      "Norm of the Residual Vector =  7.793734002518813e-15\n",
      "\n",
      "The Solution Vector x =\n",
      " [ 1.3 -0.3  4.2  4.2 -0.3  1.3]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [10. -8. 10. 10. -8. 10.] \n",
      "\t→b: [10. -8. 10. 10. -8. 10.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solve for x using the Conjugate Gradient Method\n",
    "A = array([[ 3, -2,  1,  0,  0,  1 ],\n",
    "           [-2,  4, -2,  1,  0,  0 ],\n",
    "           [ 1, -2,  4, -2,  1,  0 ],\n",
    "           [ 0,  1, -2,  4, -2,  1 ],\n",
    "           [ 0,  0,  1, -2,  4, -2 ],\n",
    "           [ 1,  0,  0,  1, -2,  3 ]], float) # note: bands are neg\n",
    "b = array( [10, -8, 10, 10, -8, 10 ], float)\n",
    "\n",
    "## Define functions for iterative technique\n",
    "def conjGrad(a, B):\n",
    "    '''\n",
    "    Function accepts a Transformation Matrix \"a\" with Output Vector \"B\"\n",
    "    when applied to some Solution Vector \"x\". Function finds x.\n",
    "    Author's Note: 'pred' == 'approximated'\n",
    "    DEFINITIONS::\n",
    "    f' :: gradient; vectors are direction (steepest increase of f), magnitude (rate of increase)\n",
    "    r :: residual vector, stores direction of steepest descent btwn pred-x and true-x; \n",
    "            r=B-a*x (keep implementing eq to update a*r product btwn alpha & new_r to avoid roundoff)\n",
    "    new_r :: next prediction for r based on previous r; new_r = prev_r-alpha*a*r\n",
    "    alpha :: step size, minimizes f per iteration by setting f'=(-r); alpha=r.T*r/r.T(a*r)\n",
    "    pred_x :: next prediction for x based on previous x; pred_x=prev_x+alpha*r\n",
    "    '''\n",
    "    n = len(B)\n",
    "    x = np.zeros(n)  # initial approximation of the solution:: set x=0\n",
    "    r = np.zeros(n)  # initial residual vector\n",
    "    r = B - np.dot(a,x)\n",
    "    s = r.copy()  # initial search vector\n",
    "    r_old = np.dot(r.T,r)\n",
    "    for i in range(n):\n",
    "        u = np.dot(a,s) # unit vectors\n",
    "        alpha = r_old / np.dot(s.T,u)\n",
    "        x += np.dot(alpha,s) # iterated solution\n",
    "        r -= np.dot(alpha,u) # updated residual\n",
    "        r_new = np.dot(r.T,r)\n",
    "        # Check whether converging\n",
    "        if(math.sqrt(np.dot(r,r))) < 1.0e-9: break\n",
    "        s = r + (r_new/r_old)*s # updated search direction\n",
    "        r_old = r_new\n",
    "    return x,i\n",
    "\n",
    "# Solution\n",
    "x, numIter = conjGrad(A,b)\n",
    "\n",
    "# Results\n",
    "if np.isnan(x).any() or (A@x).all() != b.all():\n",
    "    print('\\n--->>> The Conjugate Gradient Method cannot be applied here! <<<---\\n')\n",
    "    print('\\tA sparse matrix with symmetry is required.\\n')\n",
    "    print(\"Problematic Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x ≠ b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")\n",
    "else:\n",
    "    print(\"\\nNumber of equations ==> \",A.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", numIter)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(A @ x - b))\n",
    "    print(\"\\nThe Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620057e",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2>Question 17</h2></center>\n",
    "Modify the program in Example 2.17 (Gauss-Seidel method) so that it will solve the following equations:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & -1 & 0 & 0 & ... & 0 & 0 & 0 & 1 \\\\\n",
    "-1 & 4 & -1 & 0 & ... & 0 & 0 & 0 & 0 \\\\\n",
    "0 & -1 & 4 & -1 & ... & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & ... & -1 & 4 & -1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & ... & 0 & -1 & 4 & -1 \\\\\n",
    "1 & 0 & 0 & 0 & ... & 0 & 0 & -1 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\vdots \\\\\n",
    "x_{n-2} \\\\\n",
    "x_{n-1} \\\\\n",
    "x_n \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "100 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Run the program with $n = 20$ and compare the number of iterations with Example 2.17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "339458cb-7317-4791-8588-9b4a4307bf15",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number of equations ==>  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of equations ==>  20\n",
      "\n",
      "Total Number of Iterations = 63\n",
      "\n",
      "Relaxation factor = 1.1654978831268998\n",
      "\n",
      "Norm of the Residual Vector::\n",
      " 2.302717522444513e-09\n",
      "\n",
      "The solution Vector x =\n",
      " [-7.7350e+00 -2.0726e+00 -5.5535e-01 -1.4881e-01 -3.9872e-02 -1.0683e-02\n",
      " -2.8616e-03 -7.6311e-04 -1.9078e-04  0.0000e+00  1.9078e-04  7.6311e-04\n",
      "  2.8616e-03  1.0683e-02  3.9872e-02  1.4881e-01  5.5535e-01  2.0726e+00\n",
      "  7.7350e+00  2.8868e+01]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [  0.  -0.   0.  -0.   0.  -0.   0.  -0.   0.   0.  -0.   0.  -0.   0.\n",
      "  -0.   0.  -0.   0.  -0. 100.] \n",
      "\t→b: [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 100.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modify textbook models to solve Example 2.17 using Gauss-Seidel Method\n",
    "## Define function to re-create A according to input length 'n'\n",
    "def banded_matrix(n):\n",
    "    A0 = diags([-1,4,-1],[-1,0,1], shape=(n,n)).toarray()\n",
    "    A0[0][n-1] = 1\n",
    "    A0[n-1][0] = 1\n",
    "    b0 = np.zeros(n)\n",
    "    b0[n-1] = 100\n",
    "    return A0, b0\n",
    "\n",
    "## Define function for Gauss-Seidel iterative technique\n",
    "def gaussSeidel(a, B):\n",
    "    omega = 1.0  # no relaxation\n",
    "    k = 10\n",
    "    p = 1\n",
    "    imax = 2000  # max iterations\n",
    "    x = zeros(len(B))  # initial approximation:: set x=0\n",
    "    for i in range(1, imax):\n",
    "        xOld = x.copy()\n",
    "        for j in range(len(B)):\n",
    "            gs_update = ( B - ( a @ x - diag(a) * x ) ) / diag(a) \n",
    "        x = omega * gs_update + (1-omega) * x\n",
    "        dx = math.sqrt(np.dot(x-xOld,x-xOld))\n",
    "        if dx < 1.0e-9: return x,i,omega\n",
    "        # Compute relaxation factor after k+p iterations\n",
    "        if i == k: dx1 = dx\n",
    "        if i == k + p:\n",
    "            dx2 = dx\n",
    "            omega = 2.0/(1.0 + math.sqrt(1.0 - (dx2/dx1)**(1.0/p)))\n",
    "    print(f'\\n\\n--->>> Gauss-Seidel failed to converge within', \\\n",
    "          f'{imax} iterations <<<---\\n')\n",
    "    # Results\n",
    "    print(\"\\nNumber of equations ==> \", a.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", i)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(a @ x - B))\n",
    "    return x,i,omega\n",
    "\n",
    "# Solution\n",
    "n = eval(input(\"\\nEnter the number of equations ==> \"))\n",
    "x = np.zeros(n)\n",
    "A, b = banded_matrix(n)\n",
    "x, numIter, omega = gaussSeidel(A, b)\n",
    "\n",
    "# Results\n",
    "print(\"\\nNumber of equations ==> \",A.shape[0])\n",
    "print(\"\\nTotal Number of Iterations =\", numIter)\n",
    "print(\"\\nRelaxation factor =\", omega)\n",
    "print(\"\\nNorm of the Residual Vector::\\n\", np.linalg.norm(A @ x - b))\n",
    "print(\"\\nThe solution Vector x =\\n\", x)\n",
    "print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c362c-1538-4136-b115-65d69ec9d003",
   "metadata": {},
   "source": [
    "<br>\n",
    "Repeat the above using the $Conjugate Gradient Method$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21bceb36-64d6-47c2-9237-38150e5b0504",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number of equations ==>  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of equations ==>  20\n",
      "\n",
      "Total Number of Iterations =  9\n",
      "\n",
      "Norm of the Residual Vector =  1.5076212769453322e-14\n",
      "\n",
      "The Solution Vector x =\n",
      " [-7.7350e+00 -2.0726e+00 -5.5535e-01 -1.4881e-01 -3.9872e-02 -1.0683e-02\n",
      " -2.8616e-03 -7.6311e-04 -1.9078e-04  0.0000e+00  1.9078e-04  7.6311e-04\n",
      "  2.8616e-03  1.0683e-02  3.9872e-02  1.4881e-01  5.5535e-01  2.0726e+00\n",
      "  7.7350e+00  2.8868e+01]\n",
      "\n",
      "Verify A x = b:\n",
      "\t→A x: [  0.  -0.   0.   0.   0.  -0.   0.   0.  -0.   0.   0.   0.  -0.   0.\n",
      "  -0.  -0.   0.   0.   0. 100.] \n",
      "\t→b: [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 100.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modify textbook models to solve Example 2.17 using Conjugate Gradient Method\n",
    "## Define function to re-create A according to input length 'n'\n",
    "def banded_matrix(n):\n",
    "    A0 = diags([-1,4,-1],[-1,0,1], shape=(n,n)).toarray()\n",
    "    A0[0][n-1] = 1\n",
    "    A0[n-1][0] = 1\n",
    "    b0 = np.zeros(n)\n",
    "    b0[n-1] = 100\n",
    "    return A0, b0\n",
    "\n",
    "## Define functions for iterative technique\n",
    "def conjGrad(a, B):\n",
    "    n = len(B)\n",
    "    x = np.zeros(n)  # initial approximation:: set x=0\n",
    "    r = np.zeros(n)  # initial residual vector\n",
    "    r = B - np.dot(a,x)\n",
    "    s = r.copy()  # initial search vector\n",
    "    r_old = np.dot(r.T,r)\n",
    "    for i in range(n):\n",
    "        u = np.dot(a,s) # unit vectors\n",
    "        alpha = r_old / np.dot(s.T,u)\n",
    "        x += np.dot(alpha,s) # iterated solution\n",
    "        r -= np.dot(alpha,u) # updated residual\n",
    "        r_new = np.dot(r.T,r)\n",
    "        # Check whether converging\n",
    "        if(math.sqrt(np.dot(r,r))) < 1.0e-9: break\n",
    "        s = r + (r_new/r_old)*s # updated search direction\n",
    "        r_old = r_new\n",
    "    return x,i\n",
    "\n",
    "# Solution\n",
    "n = eval(input(\"\\nEnter the number of equations ==> \"))\n",
    "x = np.zeros(n)\n",
    "A, b = banded_matrix(n)\n",
    "x, numIter = conjGrad(A, b)\n",
    "\n",
    "# Results\n",
    "if np.isnan(x).any() or (A@x).all() != b.all():\n",
    "    print('\\n--->>> The Conjugate Gradient Method cannot be applied here! <<<---\\n')\n",
    "    print('\\tA sparse matrix with symmetry is required.\\n')\n",
    "    print(\"Problematic Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x ≠ b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")\n",
    "else:\n",
    "    print(\"\\nNumber of equations ==> \",A.shape[0])\n",
    "    print(\"\\nTotal Number of Iterations = \", numIter)\n",
    "    print(\"\\nNorm of the Residual Vector = \", np.linalg.norm(A @ x - b))\n",
    "    print(\"\\nThe Solution Vector x =\\n\", x)\n",
    "    print(\"\\nVerify A x = b:\\n\\t→A x:\", np.round((A @ x), 1), \"\\n\\t→b:\", b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855d7a6-3e4a-4388-887e-233d15affab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "--- \n",
    "--- \n",
    "\n",
    "<center><h2>Analysis</h2></center><br><br>\n",
    "\n",
    "| Iterative Method <br> Performs Best for :: | Gauss-Seidel | Conjugate Gradient |\n",
    "| --- | --- | --- |\n",
    "| Assymetric Matrices | x |  |\n",
    "| Computational Time |   | x |\n",
    "| Large Matrices | x | x |\n",
    "| Non-Diagonally Dominant|   | x |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
